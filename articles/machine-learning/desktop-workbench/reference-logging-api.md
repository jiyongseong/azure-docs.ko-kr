---
title: Azure ML 로깅 API 참조 | Microsoft Docs
description: 로깅 API 참조.
services: machine-learning
author: akshaya-a
ms.author: akannava
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.topic: article
ms.date: 09/25/2017
ms.openlocfilehash: 1906425c6657fb6232a9dc306b05f9171c9c7bef
ms.sourcegitcommit: 59914a06e1f337399e4db3c6f3bc15c573079832
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 04/19/2018
---
# <a name="logging-api-reference"></a>로깅 API 참조

Azure ML의 로깅 라이브러리를 사용하면 나중에 분석하기 위해 기록 서비스로 추적되는 메트릭과 파일을 프로그램에서 내보낼 수 있습니다. 현재는 몇 가지 기본적인 메트릭 및 파일 유형이 지원되며 지원되는 유형 집합은 향후 Python 패키지 릴리스와 함께 증가될 것입니다.

## <a name="uploading-metrics"></a>메트릭 업로드

```python
# import logging API package
from azureml.logging import get_azureml_logger

# initialize a logger object
logger = get_azureml_logger()

# log "scalar" metrics
logger.log("simple integer value", 7)
logger.log("simple float value", 3.141592)
logger.log("simple string value", "this is a string metric")

# log a list of numerical values. 
# this automatically creates a chart in the Run History details page
logger.log("chart data points", [1, 3, 5, 10, 6, 4])
```

기본적으로 모든 메트릭은 제출이 프로그램 실행을 방해하지 않도록 비동기로 제출됩니다. 다수의 메트릭이 에지 케이스로 전송되는 경우 이로 인해 순서 지정에 문제가 발생할 수 있습니다. 예를 들어 두 개의 메트릭이 동시에 기록되지만 정확한 순서가 유지되기를 사용자가 원하는 경우가 있습니다. 또 다른 경우는 페일 패스트할 가능성이 있는 것으로 알려진 코드를 실행하기 전에 메트릭을 추적해야 하는 경우입니다. 두 경우 모두 진행하기 전에 메트릭이 완전히 기록될 때까지 _대기_하는 것이 솔루션입니다.

```python
# blocking call
logger.log("my metric 1", 1).wait()
logger.log("my metric 2", 2).wait()
```

## <a name="consuming-metrics"></a>메트릭 사용

메트릭은 기록 서비스에 의해 저장되고 이를 생성한 실행에 연결됩니다. 실행 기록 탭과 아래의 CLI 명령을 사용하면 실행이 완료된 후 메트릭(및 아래 아티팩트)을 검색할 수 있습니다.

```azurecli
# show the last run
$ az ml history last

# list all past runs
$ az ml history list 

# show a paritcular run
$ az ml history info -r <runid>
```

## <a name="artifacts-files"></a>아티팩트(파일)

메트릭 외에도 사용자는 AzureML을 통해 파일을 추적할 수 있습니다. 기본적으로 프로그램의 작업 디렉터리(계산 컨텍스트의 프로젝트 폴더)와 관련된 `outputs` 폴더에 기록된 모든 파일은 기록 서비스에 업로드되고 추후 분석을 위해 추적됩니다. 주의할 점은 개별 파일 크기가 512MB보다 작아야 한다는 것입니다.


```Python
# Log content as an artifact
logger.upload("artifact/path", "This should be the contents of artifact/path in the service")
```

## <a name="consuming-artifacts"></a>아티팩트 사용

추적된 아티팩트의 콘텐츠를 인쇄하기 위해 사용자는 주어진 실행에 대한 실행 기록 탭을 사용하여 아티팩트를 **다운로드** 또는 **승격**하거나 아래 CLI 명령을 사용하여 동일한 효과를 얻을 수 있습니다.

```azurecli
# show all artifacts generated by a run
$ az ml history info -r <runid> -a <artifact/path>

# promote a particular artifact
$ az ml history promote -r <runid> -ap <artifact/prefix> -n <name of asset to create>
```
## <a name="next-steps"></a>다음 단계
- [아이리스 분류 자습서, 2부](tutorial-classifying-iris-part-2.md)에서 로깅 API의 작동 상태를 살펴봅니다.
- [Azure Machine Learning Workbench의 실행 기록 및 모델 메트릭을 사용하는 방법](how-to-use-run-history-model-metrics.md)을 검토하여 실행 기록에서 로깅 API를 어떻게 사용할 수 있는지 자세히 이해합니다.
