---
title: Azure Machine Learning 컴퓨터 비전 및 분류 모델의 정확도 향상
description: Azure Machine Learning Package for Computer Vision을 사용하여 컴퓨터 비전 이미지 분류, 개체 감지 및 이미지 유사성 모델의 정확도를 향상시키는 방법에 대해 알아봅니다.
services: machine-learning
ms.service: machine-learning
ms.component: core
ms.topic: conceptual
ms.reviewer: jmartens
ms.author: netahw
author: nhaiby
ms.date: 04/23/2018
ms.openlocfilehash: e134e1e544c51d6756d5021fef8c049fe7d8afb0
ms.sourcegitcommit: e221d1a2e0fb245610a6dd886e7e74c362f06467
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 05/07/2018
---
# <a name="improve-the-accuracy-of-computer-vision-models"></a>컴퓨터 비전 모델의 정확도 향상

**Azure Machine Learning Package for Computer Vision**을 사용하여 이미지 분류, 개체 감지 및 이미지 유사성 모델을 구축 및 배포할 수 있습니다. 이 패키지에 대해 알아보고 설치하는 방법을 알아봅니다.

이 문서에서는 이러한 모델을 세밀하게 조정하여 정확도를 높이는 방법을 알아봅니다. 

## <a name="accuracy-of-image-classification-models"></a>이미지 분류 모델의 정확도

Computer Vision 패키지는 다양한 데이터 집합에 대해 좋은 결과를 제공하기 위해 표시됩니다. 하지만 대부분의 기계 학습 프로젝트와 마찬가지로 새 데이터 집합에 대해 최상의 결과를 얻으려면 신중한 매개 변수 튜닝과 다양한 설계 결정에 대한 평가가 필요합니다. 다음 섹션에는 주어진 데이터 집합에 대한 정확도를 높이는 방법 즉, 어떤 매개 변수가 먼저 최적화하기에 가장 유망한 매개 변수인지, 이러한 매개 변수에 대해 어떤 값을 시도해야 하는지, 그리고 어떤 함정을 피해야 하는지에 대한 지침을 제공합니다.

일반적으로 딥 러닝 모델 학습은 학습 시간과 모델 정확도 사이에 상충 관계가 있습니다. Computer Vision 패키지에는 빠른 학습 속도에 중점을 두고 일반적으로 고정밀 모델을 생성하는 기본 매개 변수(아래 테이블의 첫 번째 행 참조)가 미리 설정되어 있습니다. 정밀도는 예를 들면 높은 이미지 해상도나 보다 심층적인 모델을 사용하여 향상될 수 있지만 학습 시간이 10배 이상의 비율로 증가해야 합니다.

먼저 기본 매개 변수로 작업하고, 모델을 학습시키고, 결과를 검사하고, 필요에 따라 실측 자료 주석을 수정한 다음, 학습 시간이 길어지는 매개 변수를 시도하는 것이 좋습니다(제안된 매개 변수 값은 아래 테이블 참조). 이러한 매개 변수는 기술적으로는 필요하지 않지만 이해하는 것이 좋습니다.


### <a name="best-practices-and-tips"></a>모범 사례 및 팁

* 데이터 품질: 학습 및 테스트 집합은 고품질이어야 합니다. 즉, 이미지에 정확하게 주석을 달고, 모호한 이미지는 제거합니다(예: 테니스 공이나 레몬이 있는 이미지는 육안으로 불분명해 보임). 속성은 상호 배타적입니다(즉, 각 이미지는 정확히 하나의 특성에 속함).

* DNN을 구체화하기 전에 미리 학습된 고정 DNN을 featurizer(기능 부여자)로 사용하여 SVM 분류자를 학습시켜야 합니다. 이 기능은 Computer Vision 패키지에서 지원되며 DNN 자체가 수정되지 않았으므로 학습에 필요한 시간이 길지 않습니다. 이렇게 간단한 방식으로도 좋은 정확도를 달성하는 경우가 많기 때문에 강력한 기준선을 나타냅니다. 다음 단계는 보다 높은 정확도를 제공해야 하는 DNN을 구체화하는 것입니다.

* 이미지에서 관심 있는 개체가 작으면 이미지 분류 방법이 잘 작동하지 않는 것으로 알려져 있습니다. 이런 경우 Tensorflow 기반 Computer Vision 패키지의 Faster R-CNN과 같은 개체 감지 방식을 사용하는 것이 좋습니다.

* 학습을 많이 할수록 데이터가 좋아집니다. 각 클래스마다 어림잡아 100개 이상의 예가 있어야 합니다. 즉, "개" 이미지 100개, "고양이" 이미지 100개 등이 있어야 합니다. 더 적은 수의 이미지로 모델을 학습시킬 수 있지만 좋은 결과를 내지 못할 수 있습니다.

* 학습 이미지는 GPU를 사용하여 컴퓨터에 로컬로 상주해야 하며 SSD 드라이브(HDD는 안됨)에 있어야 합니다. 그렇지 않으면 이미지 읽기로 인한 대기 시간이 학습 속도를 크게(100배까지) 감소시킬 수 있습니다.


### <a name="parameters-to-optimize"></a>최적화할 매개 변수

이러한 매개 변수에 대해 최적의 값을 찾는 것은 중요하며 정확도를 크게 높이는 경우가 많습니다.
* 학습 속도(`lr_per_mb`): 가장 중요한 매개 변수입니다. DNN 구체화 후 학습 집합의 정확도가 5%를 초과하면 대개 학습 Epoch가 너무 높거나 학습 기간이 너무 짧습니다. 특히 작은 데이터 집합의 경우 DNN은 학습 데이터에 과도하게 적합하지만 실제로는 테스트 집합에서 우수한 모델로 이어집니다. 일반적으로 초기 학습 속도가 두 배 줄어든 15Epoch를 사용합니다. 더 많은 Epoch를 사용하여 교육하면 경우에 따라 성능이 향상될 수 있습니다.

* 입력 해상도(`image_dims`): 기본 이미지 해상도는 224x224픽셀입니다. 예를 들어 500x500픽셀 또는 1000x1000픽셀과 같은 높은 이미지 해상도를 사용하면 정확도는 크게 향상되지만 DNN 구체화 속도는 감소됩니다. Computer Vision 패키지에서는 입력 해상도가 색상 채널, 이미지 폭, 이미지 높이의 튜플(예: 3, 224, 224)이며 여기서 색상 채널 수는 3(빨강-녹색-파랑 밴드)으로 설정해야 합니다.

* 모델 아키텍처(`base_model_name`): 기본 ResNet-18 모델 대신 ResNet-34 또는 ResNet-50과 같이 보다 심층적인 DNN을 시도해봅니다. Resnet-50 모델은 더 깊을 뿐만 아니라 끝에서 두 번째 계층의 출력의 크기가 2,048개 부동 소수점 수입니다(ResNet-18 및 ResNet-34 모델의 경우 512개 부동 소수점 수). 증가된 차원은 SVM 분류자를 학습시키는 대신 DNN 고정을 유지하는 경우 특히 유용할 수 있습니다.

* 미니배치 크기(`mb_size`): 미니 배치 크기가 크면 학습 시간이 빨라지지만 DNN 메모리 소비가 증가됩니다. 따라서 보다 심층적인 모델(예: ResNet-50 및 ResNet-18) 및/또는 더 높은 이미지 해상도(500\*500 픽셀 대 224\*224픽셀)를 선택하는 경우, 메모리 부족 오류를 방지하기 위해 미니배치 크기를 줄여야 합니다. 미니배치 크기를 변경할 때 아래 테이블에 표시된 것처럼 학습 속도도 조정해야 하는 경우가 많습니다.
* 드롭 아웃 속도(`dropout_rate`) 및 L2-regularizer(정규화기)(`l2_reg_weight`): 드롭 아웃 속도를 0.5(Computer Vision 패키지에서 기본값은 0.5) 이상으로 사용하고 regularizer(정규화기) 가중치(Computer Vision 패키지에서 기본값은 0.0005)를 늘려서 DNN 과적합을 줄일 수 있습니다. 특히 데이터 집합이 작은 경우 DNN 과적합을 방지하는 것이 어렵고 불가능한 경우도 많습니다.


### <a name="parameter-definitions"></a>매개 변수 정의

- **학습 속도**: 기울기 하강 학습 중 사용되는 단계 크기입니다. 너무 낮게 설정하면 모델을 학습시키는 데 Epoch가 많이 사용되며 너무 높이 설정하면 모델이 유용한 솔루션으로 수렴되지 않습니다. 일반적으로 일정은 일정 수의 Epoch 후 학습 속도가 감소되는 곳에서 사용됩니다. 예를 들어 학습 속도 일정 `[0.05]*7 + [0.005]*7 + [0.0005]`가 처음 7개 Epoch에 대해 초기 학습 속도 0.05를 사용한 후 다른 7개 Epoch에 10배 감소된 학습 속도인 0.005를 사용한 다음, 마지막으로 100배 감소된 학습 속도인 0.0005를 사용하여 단일 Epoch에 대해 모델을 미세 조정하는 것과 일치합니다.

- **미니배치 크기**: GPU는 여러 이미지를 병렬로 처리하여 계산 속도를 높일 수 있습니다. 이렇게 병렬 처리된 이미지를 미니배치라고도 합니다. 미니배치 크기가 클수록 학습 속도가 빨라지지만 DNN 메모리 소비가 증가하는 비용을 감수해야 합니다.

### <a name="recommended-parameter-values"></a>권장 매개 변수 값

아래 테이블에는 다양한 이미지 분류 작업에 대해 고정밀 모델을 생성하는 것으로 입증된 여러 가지 매개 변수 집합이 있습니다. 최적의 매개 변수는 특정 데이터 집합 및 사용된 정확한 GPU에 따라 달라지므로 테이블은 지침으로만 참고해야 합니다. 해당 매개 변수를 사용해 본 후, 500x500픽셀 이상의 이미지 해상도 또는 Resnet-101 또는 Resnet-152와 같은 보다 심층적인 모델도 고려해 보십시오.

테이블의 첫 번째 행은 Computer Vision 패키지 내에 설정된 기본 매개 변수에 해당합니다. 다른 모든 행은 학습 시간이 더 올래 걸리지만(첫 번째 열에 표시됨) 정확도가 높아지는 이점이 있습니다(두 번째 열에서 3개의 내부 데이터 집합에 대한 평균 정확도 참조). 예를 들어 마지막 행의 매개 변수는 학습에 걸리는 시간이 5-15배 더 길지만 결과적으로 내부 테스트 집합 3개의 정확도가 82.6%에서 92.8%로 증가(평균)됩니다.

보다 심층적인 모델을 사용하여 입력 해상도를 높이면 DNN 메모리가 더 많이 사용되기 때문에 메모리 부족 오류를 방지하려면 모델 복잡성을 높이고 미니배치 크기를 줄여야 합니다. 아래 테이블에서 볼 수 있듯이 미니배치 크기를 동일한 승수로 줄일 때마다 학습 속도를 2배만큼 줄이는 것이 유용합니다. 메모리 양이 작은 GPU에서는 미니배치 크기를 더 줄여야 할 수도 있습니다.

| 학습 시간(대략적인 예상) | 예제 정확도 | 미니배치 크기(*mb_size*) | 학습 속도(*lr_per_mb*) | 이미지 해상도(*image_dims*) | DNN 아키텍처(*base_model_name*) |
|------------- |:-------------:|:-------------:|:-----:|:-----:|:---:|
| 1x(참조) | 82.6% | 32 | [0.05]\*7  + [0.005]\*7  + [0.0005]  | (3, 224, 224) | ResNet18_ImageNet_CNTK |
| 2-5x    | 90.2% | 16 | [0.025]\*7 + [0.0025]\*7 + [0.00025] | (3, 500, 500) | ResNet18_ImageNet_CNTK |
| 2-5x    | 87.5% | 16 | [0.025]\*7 + [0.0025]\*7 + [0.00025] | (3, 224, 224) | ResNet50_ImageNet_CNTK |
| 5-15x        | 92.8% |  8 | [0.01]\*7  + [0.001]\*7  + [0.0001]  | (3, 500, 500) | ResNet50_ImageNet_CNTK |


## <a name="next-steps"></a>다음 단계

Azure Machine Learning Package for Computer Vision에 대한 자세한 내용은:
+ 참조 설명서를 참조하세요.

+ [Azure Machine Learning용 다른 Python 패키지](reference-python-package-overview.md)를 자세히 알아보세요.