---
title: Azure Media Services 조각화된 MP4 라이브 수집 사양 | Microsoft 문서
description: 이 사양에서는 Azure Media Services용 조각화된 MP4 기반 라이브 스트리밍 수집에 대한 프로토콜 및 형식을 설명합니다. Azure Media Services를 사용하면 클라우드 플랫폼으로 Azure를 사용하여 실시간으로 라이브 이벤트를 스트림하고 콘텐츠를 브로드캐스트할 수 있습니다. 이 문서에서는 매우 중복되고 강력한 라이브 수집 메커니즘을 구축하는 모범 사례도 다룹니다.
services: media-services
documentationcenter: ''
author: cenkdin
manager: cfowler
editor: ''
ms.assetid: 43fac263-a5ea-44af-8dd5-cc88e423b4de
ms.service: media-services
ms.workload: media
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 06/29/2017
ms.author: cenkd;juliako
ms.openlocfilehash: 367066b0073775ae10fd5e9d084c5bc78ebf6677
ms.sourcegitcommit: e221d1a2e0fb245610a6dd886e7e74c362f06467
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 05/07/2018
---
# <a name="azure-media-services-fragmented-mp4-live-ingest-specification"></a>Azure Media Services 조각화된 MP4 라이브 수집 사양
이 사양에서는 Azure Media Services용 조각화된 MP4 기반 라이브 스트리밍 수집에 대한 프로토콜 및 형식을 설명합니다. Media Services는 Azure를 클라우드 플랫폼으로 사용하여 고객이 실시간으로 라이브 이벤트를 스트림하고 콘텐츠를 브로드캐스트할 수 있는 라이브 스트리밍 서비스를 제공합니다. 이 문서에서는 매우 중복되고 강력한 라이브 수집 메커니즘을 구축하는 모범 사례도 다룹니다.

## <a name="1-conformance-notation"></a>1. 적합성 표기
이 문서의 키워드인 “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY” 및 “OPTIONAL”은 RFC 2119에 기재된 바와 같이 번역됩니다.

## <a name="2-service-diagram"></a>2. 서비스 다이어그램
다음 다이어그램에서는 Media Services에서 라이브 스트리밍 서비스에 대한 높은 수준의 아키텍처를 보여줍니다.

1. 라이브 인코더는 Azure Media Services SDK를 통해 생성되고 프로비저닝된 채널에 라이브 피드를 푸시합니다.
2. Media Services의 채널, 프로그램 및 스트리밍 끝점은 수집, 형식 지정, 클라우드 DVR, 보안, 확장성 및 중복성을 포함한 라이브 스트리밍 기능을 모두 처리합니다.
3. 고객은 필요에 따라 스트리밍 끝점과 클라이언트 끝점 사이의 Azure Content Delivery Network 레이어 배포를 선택할 수 있습니다.
4. 클라이언트 끝점은 HTTP 적응 스트리밍 프로토콜을 사용하여 스트리밍 끝점에서 스트림합니다. 예로 Microsoft 부드러운 스트리밍, HTTP를 통한 동적 적응 스트리밍(DASH 또는 MPEG-DASH) 및 Apple HLS(HTTP 라이브 스트리밍)가 있습니다.

![수집 흐름][image1]

## <a name="3-bitstream-format--iso-14496-12-fragmented-mp4"></a>3. 비트스트림 형식 - ISO 14496-12 조각화된 MP4
이 문서에서 설명하는 라이브 스트리밍 수집용 유선 형식은 [ISO-14496-12]를 기반으로 합니다. 주문형 비디오 파일 및 라이브 스트리밍 수집 모두에 대한 조각화된 MP4 형식 및 확장에 대한 자세한 내용은 [[MS-SSTR]](http://msdn.microsoft.com/library/ff469518.aspx)을 참조하세요.

### <a name="live-ingest-format-definitions"></a>라이브 수집 형식 정의
다음 목록에는 Azure Media Services에 라이브 수집을 적용하는 특별한 형식 정의가 설명되어 있습니다.

1. **ftyp**, **Live Server Manifest Box** 및 **moov** 상자는 반드시 각 요청(HTTP POST)과 함께 전송되어야 합니다. 이러한 상자는 반드시 스트림의 시작 부분에 전송되어야 하며, 스트림 수집을 계속하려면 인코더를 반드시 다시 연결해야 합니다. 자세한 내용은 [1]의 섹션 6을 참조하세요.
2. [1]의 섹션 3.3.2는 라이브 수집용 **StreamManifestBox**라는 옵션 상자를 설명합니다. Azure Load Balancer의 라우팅 논리로 인해 이 상자는 사용되지 않습니다. Media Services로 수집하는 경우 상자가 표시되어서는 안 됩니다. 이 상자가 표시되는 경우 Media Services는 자동으로 이를 무시합니다.
3. [1]의 3.2.3.2에서 설명된 **TrackFragmentExtendedHeaderBox** 상자는 반드시 조각마다 있어야 합니다.
4. **TrackFragmentExtendedHeaderBox** 상자의 버전 2를 여러 데이터 센터에서 동일한 URL로 미디어 세그먼트를 생성하는 데 사용해야 합니다. 조각 인덱스 필드는 Apple HLS 및 인덱스 기반 MPEG-DASH와 같은 인덱스 기반 스트리밍 형식의 데이터 센터 간 장애 조치(failover)에 필요합니다. 데이터 센터 간 장애 조치(failover)를 사용하려면 조각 인덱스가 반드시 여러 인코더에 걸쳐 동기화되고, 인코더 재시작 또는 오류 중에도 연속되는 각 미디어 조각에 대해 1씩 증가되어야 합니다.
5. [1]의 섹션 3.3.6은 라이브 수집의 끝에 전송되어 채널에 EOS(스트림 끝)를 나타낼 수 있는 **MovieFragmentRandomAccessBox**(**mfra**)를 정의합니다. Media Services의 수집 논리에 따라 EOS는 사용되지 않으며, 라이브 수집용 **mfra** 상자를 전송하지 않아야 합니다. 전송한 경우 Media Services는 자동으로 이를 무시합니다. 수집 지점의 상태를 다시 설정하려면 [채널 재설정](https://docs.microsoft.com/rest/api/media/operations/channel#reset_channels)을 사용하는 것이 좋습니다. 프레젠테이션 및 스트림을 종료하려면 [프로그램 중지](https://msdn.microsoft.com/library/azure/dn783463.aspx#stop_programs)를 사용하는 것이 좋습니다.
6. MP4 조각 기간은 클라이언트 매니페스트의 크기를 줄이도록 일정해야 합니다. 또한 일정한 MP4 조각 기간은 반복 태그를 사용함으로써 클라이언트 다운로드 추론을 향상시킵니다. 이 기간은 정수가 아닌 프레임 속도에 대한 보정을 위해 변동될 수도 있습니다.
7. MP4 조각 기간은 약 2~6초 사이여야 합니다.
8. MP4 조각 타임스탬프 및 인덱스(**TrackFragmentExtendedHeaderBox** `fragment_ absolute_ time` 및 `fragment_index`)는 오름차순으로 도착해야 합니다. Media Services는 중복 조각에 대한 복원력이 뛰어나지만 미디어 타임라인에 따라 조각의 순서를 다시 지정하는 기능은 한정적입니다.

## <a name="4-protocol-format--http"></a>4. 프로토콜 형식 – HTTP
Media Services용 ISO 조각화된 MP4 기반 라이브 수집은 표준 장기 실행 HTTP POST 요청을 사용하여 조각화된 MP4 형식으로 패키징된 인코딩된 미디어 데이터를 서비스에 전송합니다. 각 HTTP POST는 헤더 상자(**ftyp**, **Live Server Manifest Box** 및 **moov** 상자)로 시작되고 조각의 시퀀스(**moof** 및 **mdat** 상자)로 계속되는 전체 조각화된 MP4 비트스트림(“스트림”)을 전송합니다. HTTP POST 요청에 대한 URL 구문은 [1]의 섹션 9.2를 참조하세요. POST URL의 예는 다음과 같습니다. 

    http://customer.channel.mediaservices.windows.net/ingest.isml/streams(720p)

### <a name="requirements"></a>요구 사항
자세한 요구 사항은 다음과 같습니다.

1. 인코더는 동일한 수집 URL을 사용하는 “본문”이 빈(콘텐츠 길이가 0인) HTTP POST 요청을 전송하여 브로드캐스트를 시작해야 합니다. 이는 라이브 수집 끝점이 유효한지, 인증이나 다른 조건이 필요한지를 인코더가 신속하게 감지하는 데 도움이 됩니다. HTTP 프로토콜마다 서버는 POST 본문을 포함하는 모든 요청을 수신할 때까지 HTTP 응답을 다시 보낼 수 없습니다. 이 단계가 없으면 라이브 이벤트의 장기 실행 특성에 따라 인코더는 모든 데이터 전송을 마칠 때까지 어떤 오류도 감지하지 못할 수도 있습니다.
2. 인코더는 (1) 때문에 모든 오류 또는 인증 과제를 반드시 처리해야 합니다. (1)이(가) 200 응답에 성공하면 계속합니다.
3. 인코더는 반드시 조각화된 MP4 스트림을 사용하여 새 HTTP POST 요청을 시작해야 합니다. 페이로드는 반드시 조각 다음의 헤더 상자로 시작해야 합니다. 이전 요청이 스트림의 끝 이전에 종료되어서 인코더를 다시 연결해야 하는 경우에도 **ftyp**, **Live Server Manifest Box** 및 **moov** 상자(이 순서로)는 반드시 각 요청과 함께 전송되어야 합니다. 
4. 라이브 이벤트의 전체 콘텐츠 길이를 예측하는 것은 불가능하므로 인코더는 반드시 업로딩에 대해 청크된 전송 인코딩을 사용해야 합니다.
5. 이벤트가 끝나면, 마지막 조각을 전송한 후 인코더는 반드시 청크된 전송 인코딩 메시지 시퀀스를 정상적으로 끝내야 합니다(대부분의 HTTP 클라이언트 스택은 자동으로 처리합니다). 인코더는 반드시 서비스가 마지막 응답 코드를 반환할 때까지 대기한 다음, 연결을 종료해야 합니다. 
6. 인코더는 결코 Media Services로의 라이브 수집을 위해 [1]의 9.2에 설명한 `Events()` 명사를 사용하면 안 됩니다.
7. HTTP POST 요청이 스트림의 끝 이전에 TCP 오류로 종료되거나 시간 초과된 경우, 인코더는 반드시 새 연결을 사용하여 새 POST 요청을 발행하고 이전 요구 사항을 따라야 합니다. 또한 인코더는 반드시 스트림에 각 추적에 대한 이전 두 MP4 조각을 다시 전송하고, 미디어 타임라인에서 불연속성을 발생시키지 않고 다시 시작해야 합니다. 각 트랙에 대해 마지막 2개의 MP4 조각을 다시 전송하여 데이터 손실이 없음을 보증합니다. 즉, 하나의 스트림이 오디오 및 비디오 트랙을 모두 포함하고 현재의 POST 요청이 실패한 경우, 데이터 손실이 없도록 인코더는 반드시 다시 연결하고 이전에 성공적으로 전송된 오디오 트랙에 대해 마지막 2개의 조각 및 이전에 성공적으로 전송된 비디오 트랙에 대해 마지막 2개의 조각을 다시 전송해야 합니다. 인코더는 반드시 다시 연결될 때 다시 전송되는 미디어 조각의 “정방향” 버퍼를 유지해야 합니다.

## <a name="5-timescale"></a>5. 시간 간격
[[MS-SSTR]](https://msdn.microsoft.com/library/ff469518.aspx)은 **SmoothStreamingMedia**(섹션 2.2.2.1), **StreamElement**(섹션 2.2.2.3), **StreamFragmentElement**(섹션 2.2.2.6) 및 **LiveSMIL**(섹션 2.2.7.3.1)에 대한 시간 간격의 사용법에 대해 설명합니다. 시간 간격 값이 없는 경우 사용되는 기본값은 10,000,000(10MHz)입니다. 부드러운 스트리밍 형식 사양이 다른 시간 간격 값을 차단하지 않더라도 대부분의 인코더 구현은 이 기본값(10MHz)을 사용하여 부드러운 스트리밍 수집 데이터를 생성합니다. [Azure 미디어 동적 패키징](media-services-dynamic-packaging-overview.md) 기능에 따라 비디오 스트림에는 90KHz 시간 간격을, 오디오 스트림에는 44.1KHz 또는 48.1KHz를 사용하는 것이 좋습니다. 다른 스트림에 다른 시간 간격 값이 사용되는 경우 스트림 수준 시간 간격은 반드시 전송되어야 합니다. 자세한 내용은 [[MS-SSTR]](https://msdn.microsoft.com/library/ff469518.aspx)을 참조하세요.     

## <a name="6-definition-of-stream"></a>6. “스트림”의 정의
스트림은 라이브 프레젠테이션 작성, 스트리밍 장애 조치(failover) 및 중복성 시나리오 처리를 위한 라이브 수집의 기본 작업 단위입니다. 스트림은 단일 트랙 또는 여러 트랙을 포함할 수 있는 하나의 고유한 조각화된 MP4 비트스트림으로 정의됩니다. 전체 라이브 프레젠테이션은 라이브 인코더의 구성에 따라 하나 이상의 스트림을 포함할 수 있습니다. 다음 예에서는 스트림을 사용하여 전체 라이브 프레젠테이션을 작성하는 다양한 옵션을 설명합니다.

**예제:** 

고객은 다음 오디오/비디오 비트 전송률을 포함하는 라이브 스트리밍 프레젠테이션을 생성하고자 합니다.

비디오 - 3000kbps, 1500kbps, 750kbps

오디오 - 128kbps

### <a name="option-1-all-tracks-in-one-stream"></a>옵션 1: 모든 트랙을 하나의 스트림에
이 옵션에서는 단일 인코더가 모든 오디오/비디오 트랙을 생성한 다음 하나의 조각화된 MP4 비트스트림으로 번들화합니다. 그런 다음 조각화된 MP4 비트스트림이 단일 HTTP POST 연결을 통해 전송됩니다. 이 예제에서는 이 라이브 프레젠테이션에 스트림이 하나만 존재합니다.

![스트림 - 한 트랙][image2]

### <a name="option-2-each-track-in-a-separate-stream"></a>옵션 2: 각각의 트랙을 별도의 스트림에
이 옵션에서는 인코더가 하나의 트랙을 각 조각화된 MP4 비트스트림에 배치하고 모든 스트림을 개별 HTTP 연결을 통해 게시합니다. 이는 하나 이상의 인코더로 수행할 수 있습니다. 라이브 수집 관점에서 이 라이브 프레젠테이션은 4개의 스트림으로 구성됩니다.

![스트림 - 별도 트랙][image3]

### <a name="option-3-bundle-audio-track-with-the-lowest-bitrate-video-track-into-one-stream"></a>옵션 3: 오디오 트랙과 가장 낮은 비트 전송률의 비디오 트랙을 하나의 스트림에 번들화
이 옵션에서 고객은 오디오 트랙과 가장 낮은 비트 전송률의 비디오 트랙을 하나의 조각화된 MP4 비트스트림에 번들화하고 다른 2개의 비디오 트랙은 각각 자체 스트림에 남겨두도록 선택합니다. 

![스트림 - 오디오 및 비디오 트랙][image4]

### <a name="summary"></a>요약
이는 이 예제에서 가능한 모든 수집 옵션의 완벽한 목록은 아닙니다. 사실상 어떤 트랙을 스트림에 그룹화하는 것은 라이브 수집에서 지원됩니다. 고객 및 인코더 공급 업체는 엔지니어링 복잡성, 인코더 용량 및 중복성과 장애 조치 고려 사항에 따라 고유한 구현을 선택할 수 있습니다. 그러나 대부분의 경우 전체 라이브 프레젠테이션에 대해 하나의 오디오 트랙만 존재합니다. 따라서 오디오 트랙을 포함하는 수집 스트림의 온전성을 확인하는 것이 중요합니다. 이 고려 사항은 오디오 트랙을 자체 스트림에 배치하는 경우(옵션 2)나 가장 낮은 비트 전송률의 비디오 트랙에 번들화하는 경우(옵션 3)에 종종 발생합니다. 또한 중복성과 내결함성을 향상시키기 위해 동일한 오디오 트랙을 2개의 다른 스트림으로 전송하는 경우(중복 오디오 트랙을 사용한 옵션 2)나 오디오 트랙을 2개 이상의 가장 낮은 비트 전송률의 비디오 트랙에 번들화하는 경우(2개 이상의 비디오 스트림에 오디오를 번들화하는 옵션 3)는 Media Services의 라이브 수집에 적극 권장됩니다.

## <a name="7-service-failover"></a>7. 서비스 장애 조치(failover)
라이브 스트리밍의 특성상 양호한 장애 조치 지원은 서비스의 가용성을 보장하는 데 매우 중요합니다. Media Services는 네트워크 오류, 서버 오류 및 저장소 문제를 포함하는 다양한 오류 형식을 처리하도록 설계되었습니다. 라이브 인코더 측의 적절한 장애 조치(failover) 논리와 함께 사용하면 고객은 클라우드에서 매우 안정적인 라이브 스트리밍 서비스를 달성할 수 있습니다.

이 섹션에서는 서비스 장애 조치(failover) 시나리오를 설명합니다. 이 경우 서비스 내 어딘가에서 오류가 발생하고 자체적으로 네트워크 오류로 매니페스트합니다. 다음은 서비스 장애 조치를 처리하기 위한 인코더 구현에 대한 몇 가지 권장 사항입니다.

1. TCP 연결을 설정하는 데 10초 시간 제한을 사용합니다. 연결을 설정하려는 시도가 10 초 이상 걸리는 경우, 작업을 중단하고 다시 시도하세요. 
2. HTTP 요청 메시지 청크를 보려면 짧은 제한 시간을 사용하세요. 대상 MP4 조각 기간이 N초인 경우, N ~ 2N초의 전송 시간 제한을 사용합니다. 예를 들어 MP4 조각 기간이 6초인 경우 6 ~ 12초 시간 제한을 사용합니다. 시간 초과가 발생하면 연결을 다시 설정하고, 새 연결을 열고, 새 연결에서 스트림 수집을 계속합니다. 
3. 서비스에 성공적으로 온전히 전송된 각 트랙에 대한 마지막 두 조각을 포함하는 롤링 버퍼를 유지합니다.  스트림에 대한 HTTP POST 요청이 종료되거나 스트림이 끝나기 전에 제한 시간을 초과하는 경우, 새 연결을 열고 다른 HTTP POST 요청을 시작하며 스트림 헤더를 다시 전송하고, 각 트랙의 마지막 두 조각을 다시 전송한 후 미디어 타임 라인에서 불연속성을 발생시키지 않고 스트림을 계속합니다. 이렇게 하면 데이터가 손실될 가능성이 줄어듭니다.
4. 인코더는 연결을 설정하거나 TCP 오류가 발생한 후 스트리밍을 계속하는 재시도 횟수를 제한하지 않는 것이 좋습니다.
5. TCP 오류 후:
  
    a. 현재 연결을 반드시 닫고, 새 HTTP POST 요청에 대한 새 연결을 반드시 생성해야 합니다.

    나. 새 HTTP POST URL은 초기 POST URL과 반드시 동일해야 합니다.
  
    다. 새 HTTP POST는 반드시 초기 POST의 스트림 헤더와 동일한 스트림 헤더(**ftyp**, **Live Server Manifest Box** 및 **moov** 상자)를 포함해야 합니다.
  
    d. 반드시 각 트랙에 전송된 마지막 두 조각이 다시 전송되고, 미디어 타임라인에서 불연속성을 발생시키지 않고 스트리밍이 계속되어야 합니다. MP4 조각 타임 스탬프는 HTTP POST 요청 간에도 반드시 지속적으로 증가해야 합니다.
6. MP4 조각 기간에 상응하는 속도로 데이터가 전송되고 있지 않은 경우 인코더는 HTTP POST 요청을 종료해야 합니다.  데이터를 전송하지 않는 HTTP POST 요청은 Media Services가 서비스 업데이트 발생 시 인코더에서 연결이 빨리 끊어지는 것을 방지할 수 있습니다. 따라서 스파스 조각이 전송되면 즉시 종료되는 스파스(광고 신호) 트랙용 HTTP POST는 수명이 짧아야 합니다.

## <a name="8-encoder-failover"></a>8. 인코더 장애 조치(failover)
인코더 장애 조치는 종단간 라이브 스트리밍 배달에 대해 해결해야 하는 장애 조치 시나리오의 두 번째 형식입니다. 이 시나리오에서는 오류 조건이 인코더 쪽에서 발생합니다. 

![인코더 장애 조치(failover)][image5]

다음은 인코더 장애 조치(failover)가 발생했을 때 라이브 수집 끝점부터 적용되는 내용입니다.

1. 다이어그램에 나타난 것처럼 새 인코더 인스턴스를 생성하여 스트리밍을 계속해야 합니다(파선이 있는 3000k 비디오용 스트림).
2. 새 인코더는 반드시 실패한 인스턴스인 HTTP POST 요청에 대해 동일한 URL을 사용해야 합니다.
3. 새 인코더의 POST 요청은 반드시 실패한 인스턴스인 동일한 조각화된 MP4 헤더 상자를 포함해야 합니다.
4. 새 인코더는 반드시 동일한 라이브 프레젠테이션에 대해 실행 중인 다른 모든 인코더와 올바르게 동기화되어 조각 경계로 정렬된 동기화된 오디오/비디오 샘플을 생성해야 합니다.
5. 새 스트림은 반드시 이전 스트림과 의미적으로 동등해야 하며 헤더 및 조각 수준에서 바꿔 사용할 수 있어야 합니다.
6. 데이터 손실을 최소화하기 위해 새 인코더를 시도해야 합니다. 인코더가 마지막으로 중지된 지점에서 미디어 조각의 `fragment_absolute_time` 및 `fragment_index`를 증가시켜야 합니다. `fragment_absolute_time` 및 `fragment_index`는 지속적으로 증가해야 하지만, 필요에 따라 불연속적인 것도 허용됩니다. Media Services는 이미 수신하고 처리된 조각을 무시하므로 미디어 타임라인에서 불연속적인 것보다 조각 재전송 면에서 더 낫습니다. 

## <a name="9-encoder-redundancy"></a>9. 인코더 중복성
높은 가용성과 고품질 환경이 요구되는 특정 중요한 라이브 이벤트의 경우, 데이터 손실 없이 원활하게 장애 조치(failover)를 달성하기 위해 활성-활성 중복 인코더를 사용하는 것이 좋습니다.

![인코더 중복성][image6]

이 다이어그램에서 볼 수 있듯이, 라이브 서비스에 각 스트림의 두 복사본을 동시에 푸시하는 두 인코더 그룹이 있습니다. 이 설정은 Media Services가 중복된 조각을 스트림 ID와 조각 타임스탬프에 따라 필터링할 수 있기 때문에 지원됩니다. 라이브 스트림의 결과 및 보관은 2개의 소스에서 가능한 최상의 집계인 모든 스트림의 복사본으로 단일화됩니다. 예를 들어 가상의 극단적인 경우에, 하나의 인코더(동일한 것은 아니어도 됨)가 각 스트림에 대해 지정된 지점에서 가동하는 한 서비스의 라이브 스트림 결과는 데이터 손실 없이 연속됩니다. 

이 시나리오에 대한 요청은 두 번째 인코더 집합이 기본 인코더와 같은 시간에 실행되는 경우 외에는 “인코더 장애 조치(failover)” 사례의 요청과 거의 동일합니다.

## <a name="10-service-redundancy"></a>10. 서비스 중복성
중복성이 높은 글로벌 배포의 경우, 때때로 지역적 재해를 처리하기 위해 하위 지역 간 백업이 필요합니다. “인코더 중복성” 토폴로지를 확장하기 위해 고객은 두 번째 인코더 집합과 연결된 다른 하위 지역에서 중복 서비스를 배포하도록 선택할 수 있습니다. 또한 고객은 클라이언트 트래픽을 원활하게 라우팅하도록 두 서비스 배포에 앞서 Content Delivery Network 공급자와 함께 작업하여 Global Traffic Manager를 배포할 수 있습니다. 인코더에 대한 요구 사항은 “인코더 중복” 사례와 동일합니다. 유일한 예외는 두 번째 인코더 집합이 다른 라이브 수집 끝점을 가리켜야 한다는 점입니다. 다음 다이어그램은 이 설정을 보여 줍니다.

![서비스 중복성][image7]

## <a name="11-special-types-of-ingestion-formats"></a>11. 수집 형식의 특수한 유형
이 섹션에서는 특정 시나리오를 처리하기 위해 설계된 라이브 수집 형식의 특수한 유형을 설명합니다.

### <a name="sparse-track"></a>스파스 트랙
클라이언트 환경이 풍부한 라이브 스트리밍 프레젠테이션을 제공하는 경우, 주 미디어 데이터와 함께 시간 동기화된 이벤트 또는 신호가 포함된 대역을 전송해야 하는 경우가 종종 있습니다. 동적 라이브 광고 삽입이 하나의 예입니다. 이벤트 신호 보내기의 이 유형은 스파스 특성 때문에 일반적인 오디오/비디오 스트리밍과 다릅니다. 즉, 신호 보내기 데이터는 일반적으로 연속적으로 발생하지 않으며 간격을 예측하기 어렵습니다. 스파스 트랙의 개념은 대역에 포함된 신호 보내기 데이터를 수집하고 브로드캐스트하기 위해 설계되었습니다.

다음 단계는 스파스 트랙 수집의 바람직한 구현입니다.

1. 오디오/비디오 트랙 없이 스파스 트랙만 포함하는 별도의 조각화된 MP4 비트스트림을 생성합니다.
2. [1]의 섹션 6에서 정의된 **Live Server Manifest Box**에서 *parentTrackName* 매개 변수를 사용하여 부모 트랙의 이름을 지정합니다. 자세한 내용은 [1]의 섹션 4.2.1.2.1.2를 참조하세요.
3. **Live Server Manifest Box**에서 **manifestOutput**을 반드시 **true**로 설정해야 합니다.
4. 신호 보내기 이벤트의 스파스 특성에 따라 다음이 권장됩니다.
   
    a. 라이브 이벤트의 시작 부분에서 서비스가 클라이언트 매니페스트의 스파스 트랙을 등록하도록 인코더가 초기 헤더 상자를 서비스에 전송합니다.
   
    나. 인코더는 데이터가 전송되지 않을 때 HTTP POST 요청을 종료해야 합니다. 데이터를 전송하지 않는 HTTP POST는 Media Services가 서비스 업데이트 또는 서버 다시 시작 시 인코더에서 연결이 빨리 끊어지는 것을 방지할 수 있습니다. 이러한 경우에 미디어 서버는 소켓의 수신 작업에서 일시적으로 차단됩니다.
   
    다. 신호 보내기 데이터를 사용할 수 없는 시간 동안 인코더는 HTTP POST 요청을 닫아야 합니다. POST 요청이 활성화되어 있는 동안 인코더는 데이터를 전송해야 합니다.

    d. 스파스 조각을 전송하는 경우 인코더는 명시적 콘텐츠-길이 헤더를 사용할 수 있는 경우 이를 설정할 수 있습니다.

    e. 새 연결로 스파스 조각을 전송하는 경우 인코더는 새 조각 다음의 헤더 박스부터 전송을 시작해야 합니다. 이는 장애 조치(failover) 사이에 발생한 사건을 위한 것이며, 이전에 스파스 트랙을 찾을 수 없었던 새 서버에 새 스파스 연결이 구축됩니다.

    f. 스파스 트랙 조각은 이와 동등하거나 더 큰 타임스탬프 값을 갖는 해당 부모 트랙 조각이 클라이언트에게 제공될 때 클라이언트에게 제공됩니다. 예를 들어, 스파스 조각의 타임스탬프가 t=1000인 경우, 타임스탬프가 1000 이상인 “비디오”(부모 트랙 이름이 “비디오”인 것으로 간주함) 조각을 클라이언트가 본 후 t=1000인 스파스 조각을 다운로드할 수 있을 것으로 예상됩니다. 실제 신호는 지정된 용도에 맞는 프레젠테이션 타임라인에서 서로 다른 위치에 사용될 수 있음에 주의하세요. 이 예제에서, t=1000인 스파스 조각은 몇 초 늦은 위치에 광고를 삽입하는 XML 페이로드를 가질 수 있습니다.

    g. 스파스 트랙 조각의 페이로드는 시나리오에 따라 서로 다른 형식(예: XML, 텍스트 또는 이진)이 될 수 있습니다.

### <a name="redundant-audio-track"></a>중복 오디오 트랙
일반적인 HTTP 적응 스트리밍 시나리오(예: 부드러운 스트리밍 또는 DASH)는 전체 프레젠테이션에 오디오 트랙이 하나만 있는 경우가 많습니다. 클라이언트에 대해 여러 개의 품질 수준을 가져서 오류 조건에서 선택할 수 있는 비디오 트랙과는 달리, 오디오 트랙은 손상된 오디오 트랙을 포함하는 스트림을 수집한 경우 단일 실패 지점이 될 수 있습니다. 

이 문제를 해결하기 위해 Media Services는 중복 오디오 트랙의 라이브 수집을 지원합니다. 동일한 오디오 트랙을 다른 스트림에서 여러 번 전송할 수 있다는 점에서 착안하였습니다. 서비스가 클라이언트 매니페스트에 오디오 트랙을 한 번 등록만 해도, 기본 오디오 트랙에 문제가 있는 경우 오디오 조각 검색을 위한 백업으로 중복된 오디오 트랙을 사용할 수 있습니다. 중복 오디오 트랙을 수집하려면 인코더는 다음을 수행해야 합니다.

1. 여러 조각화된 MP4 비트스트림에서 동일한 오디오 트랙을 만듭니다. 중복 오디오 트랙은 반드시 동일한 조각 타임스탬프와 의미상 동일해야 하며, 헤더 및 조각 수준에서 교환할 수 있어야 합니다.
2. 라이브 서버 매니페스트에서 “오디오” 항목([1]의 섹션 6)이 모든 중복 오디오 트랙에서 동일한지 확인합니다.

다음은 중복 오디오 트랙의 바람직한 구현입니다.

1. 하나의 스트림에서 자체적으로 고유한 각 오디오 트랙을 전송합니다. 또한 HTTP POST URL: {protocol}://{server address}/{publishing point path}/Streams({identifier})에서 첫 번째 스트림과 두 번째 스트림이 식별자만 다른 경우 이 오디오 트랙 스트림 각각에 대해 중복 스트림을 전송합니다.
2. 별도 스트림을 사용하여 2개의 가장 낮은 비디오 비트 전송률을 전송합니다. 이 스트림 각각은 각 고유한 오디오 트랙 각각의 복사본도 포함해야 합니다. 예를 들어, 여러 언어가 지원되는 경우 이 스트림은 각 언어에 대한 오디오 트랙을 포함해야 합니다.
3. 별도 서버(인코더) 인스턴스를 사용하여 인코딩하고 (1) 및 (2)에 언급된 중복 스트림을 전송합니다. 

## <a name="media-services-learning-paths"></a>Media Services 학습 경로
[!INCLUDE [media-services-learning-paths-include](../../../includes/media-services-learning-paths-include.md)]

## <a name="provide-feedback"></a>피드백 제공
[!INCLUDE [media-services-user-voice-include](../../../includes/media-services-user-voice-include.md)]

[image1]: ./media/media-services-fmp4-live-ingest-overview/media-services-image1.png
[image2]: ./media/media-services-fmp4-live-ingest-overview/media-services-image2.png
[image3]: ./media/media-services-fmp4-live-ingest-overview/media-services-image3.png
[image4]: ./media/media-services-fmp4-live-ingest-overview/media-services-image4.png
[image5]: ./media/media-services-fmp4-live-ingest-overview/media-services-image5.png
[image6]: ./media/media-services-fmp4-live-ingest-overview/media-services-image6.png
[image7]: ./media/media-services-fmp4-live-ingest-overview/media-services-image7.png
